{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#必要なライブラリをインポート\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#レビュアーのID、名前、レビュー数、最終投稿日を取得\n",
    "\n",
    "#リストを用意\n",
    "ID1_list = []\n",
    "Name_list = []\n",
    "nReview_list = []\n",
    "lastReview_list = []\n",
    "\n",
    "#URL（レビュアーリストの1ページ目）\n",
    "reviewer_url = 'https://www.jtnews.jp/cgi-bin_o/revlist.cgi?PAGE_NO='\n",
    "\n",
    "for i in range(1,134):\n",
    "    reviewer_url_no = reviewer_url + str(i)\n",
    "\n",
    "    #データ取得\n",
    "    result = requests.get(reviewer_url_no)\n",
    "    c = result.content\n",
    "\n",
    "    #HTMLを元に、オブジェクトを作る\n",
    "    soup = BeautifulSoup(c, \"lxml\")\n",
    "\n",
    "    #リストの部分を切り出し\n",
    "    summary = soup.find_all(\"td\",{'valign':'TOP'})\n",
    "    \n",
    "    #2つのテーブルを抜き出し\n",
    "    tables = summary[2].find_all('table',{'bgcolor':'#4499FF'})\n",
    "    \n",
    "    #レビュアーリストの方からtrを抜き出し\n",
    "    trs = tables[1].find_all('tr')\n",
    "    \n",
    "    #ページ内のレビュアー情報をループして取得\n",
    "    for i in range(2,len(trs)):\n",
    "        ths = trs[i].find('th') #No\n",
    "        tds = trs[i].find_all('td') #名前、レビュー数、最終レビュー日\n",
    "\n",
    "        #Noを取得\n",
    "        No = str(ths)\n",
    "        No = No.replace('<th><font color=\"GREEN\">','')\n",
    "        No = No.replace('</font></th>','')\n",
    "        Replace_str = '<td><a href=\"revper.cgi?&amp;REVPER_NO=' + No + '\">' #名前部分から文字列を削除するために用意\n",
    "        ID1_list.append(No)\n",
    "\n",
    "        #名前を取得\n",
    "        Name = str(tds[0])\n",
    "        Name = Name.replace('</a>さん</td>','')\n",
    "        Name = Name.replace(Replace_str, '')\n",
    "        Name_list.append(Name)\n",
    "\n",
    "        #レビュー数を取得\n",
    "        nReview = str(tds[1])\n",
    "        nReview = nReview.replace('<td>','')\n",
    "        nReview = nReview.replace('</td>','')\n",
    "        nReview_list.append(nReview)\n",
    "\n",
    "        #最終レビュー日を取得\n",
    "        lastReview = str(tds[2])\n",
    "        lastReview = lastReview.replace('<td>','')\n",
    "        lastReview = lastReview.replace('</td>','')\n",
    "        lastReview_list.append(lastReview)\n",
    "        \n",
    "    time.sleep(3) #待機"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#レビュアーの性別と年齢を取得\n",
    "\n",
    "#リストを用意\n",
    "gender_list = []\n",
    "age_list = []\n",
    "\n",
    "url = 'https://www.jtnews.jp/cgi-bin_o/revper.cgi?&REVPER_NO='\n",
    "\n",
    "for ID in ID1_list:\n",
    "    individual_first_url = url + str(ID)\n",
    "\n",
    "    #データ取得\n",
    "    result = requests.get(individual_first_url)\n",
    "    c = result.content\n",
    "\n",
    "    #HTMLを元に、オブジェクトを作る\n",
    "    soup = BeautifulSoup(c, \"lxml\")\n",
    "\n",
    "    #リストの部分を切り出し\n",
    "    summary = soup.find_all(\"td\",{'valign':'TOP'})\n",
    "\n",
    "    #2つのテーブルを抜き出し\n",
    "    tables = summary[2].find_all('table',{'bgcolor':'#4499FF'})\n",
    "\n",
    "    #プロフィールの方からtrを抜き出し\n",
    "    fonts = tables[0].find_all('font', {'color':'GREEN'})\n",
    "\n",
    "    gender = False\n",
    "    age = False\n",
    "\n",
    "    for font in fonts:\n",
    "        if '性別' in font:\n",
    "            gender = True\n",
    "        if '年齢' in font:\n",
    "            age = True\n",
    "\n",
    "    #プロフィールの方からtrを抜き出し\n",
    "    trs = tables[0].find_all('tr', {'bgcolor':'#FFFFFF'})\n",
    "\n",
    "    for tr in trs:\n",
    "        tr = str(tr)\n",
    "        if '性別' in tr:\n",
    "            gender = tr.replace(\n",
    "                '<tr bgcolor=\"#FFFFFF\"><th align=\"LEFT\"><font color=\"GREEN\">性別</font></th><td>\\r\\n','')\n",
    "            gender = gender.replace(\n",
    "                '<tr bgcolor=\"#FFFFFF\"><th align=\"LEFT\"><font color=\"GREEN\">性別</font></th><td>\\n','')\n",
    "            gender = gender.replace('</td></tr>','')\n",
    "            gender_list.append(gender)\n",
    "        if '年齢' in tr:\n",
    "            age = tr.replace(\n",
    "                '<tr bgcolor=\"#FFFFFF\"><th align=\"LEFT\"><font color=\"GREEN\">年齢</font></th><td>\\r\\n','')\n",
    "            age = age.replace('</td></tr>','')\n",
    "            age_list.append(age)\n",
    "        time.sleep(1) #待機\n",
    "\n",
    "    if gender == False:\n",
    "        gender_list.append('')\n",
    "    if age == False:\n",
    "        age_list.append('')\n",
    "\n",
    "    time.sleep(8) #待機"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ID1_list = Series(ID1_list)\n",
    "Name_list = Series(Name_list)\n",
    "nReview_list = Series(nReview_list)\n",
    "lastReview_list = Series(lastReview_list)\n",
    "gender_list = Series(gender_list)\n",
    "age_list = Series(age_list)\n",
    "\n",
    "movie_reviewer_df = pd.concat([ID1_list, Name_list, gender_list, age_list, nReview_list, lastReview_list],axis=1)\n",
    "\n",
    "#カラム名\n",
    "movie_reviewer_df.columns=['ID1','Name','Gender','Age','nReview','last_Review']\n",
    "\n",
    "#csvファイルとして保存\n",
    "movie_reviewer_df.to_csv('movie_reviewer.csv', sep = '\\t',encoding='utf-16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movie_reviewer = pd.read_csv('movie_reviewer.csv', sep='\\t', encoding='utf-16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID1_list = []\n",
    "ID1_list = movie_reviewer['ID1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#リスト分割関数\n",
    "def split_array(ar, n_group):\n",
    "    for i_chunk in range(n_group):\n",
    "        yield ar[i_chunk * len(ar) // n_group:(i_chunk + 1) * len(ar) // n_group]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#小分けにクローリングするために分割\n",
    "ID1_list_split = [list(r) for r in split_array(ID1_list, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='www.jtnews.jp', port=443): Max retries exceeded with url: /cgi-bin_o/revper.cgi?&REVPER_NO=25482 (Caused by NewConnectionError('<requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x11bda4358>: Failed to establish a new connection: [Errno 60] Operation timed out',))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/Users/shokosaka/anaconda/lib/python3.6/site-packages/requests/packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    140\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 141\u001b[0;31m                 (self.host, self.port), self.timeout, **extra_kw)\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shokosaka/anaconda/lib/python3.6/site-packages/requests/packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shokosaka/anaconda/lib/python3.6/site-packages/requests/packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTimeoutError\u001b[0m: [Errno 60] Operation timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/Users/shokosaka/anaconda/lib/python3.6/site-packages/requests/packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shokosaka/anaconda/lib/python3.6/site-packages/requests/packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shokosaka/anaconda/lib/python3.6/site-packages/requests/packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m    843\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sock'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 844\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shokosaka/anaconda/lib/python3.6/site-packages/requests/packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0;31m# Add certificate verification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shokosaka/anaconda/lib/python3.6/site-packages/requests/packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    149\u001b[0m             raise NewConnectionError(\n\u001b[0;32m--> 150\u001b[0;31m                 self, \"Failed to establish a new connection: %s\" % e)\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x11bda4358>: Failed to establish a new connection: [Errno 60] Operation timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/Users/shokosaka/anaconda/lib/python3.6/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    437\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m                 )\n",
      "\u001b[0;32m/Users/shokosaka/anaconda/lib/python3.6/site-packages/requests/packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    648\u001b[0m             retries = retries.increment(method, url, error=e, _pool=self,\n\u001b[0;32m--> 649\u001b[0;31m                                         _stacktrace=sys.exc_info()[2])\n\u001b[0m\u001b[1;32m    650\u001b[0m             \u001b[0mretries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shokosaka/anaconda/lib/python3.6/site-packages/requests/packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='www.jtnews.jp', port=443): Max retries exceeded with url: /cgi-bin_o/revper.cgi?&REVPER_NO=25482 (Caused by NewConnectionError('<requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x11bda4358>: Failed to establish a new connection: [Errno 60] Operation timed out',))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-7fadd2ee6316>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#待機\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;31m#データ取得\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shokosaka/anaconda/lib/python3.6/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shokosaka/anaconda/lib/python3.6/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shokosaka/anaconda/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    516\u001b[0m         }\n\u001b[1;32m    517\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shokosaka/anaconda/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shokosaka/anaconda/lib/python3.6/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    500\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mProxyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mClosedPoolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='www.jtnews.jp', port=443): Max retries exceeded with url: /cgi-bin_o/revper.cgi?&REVPER_NO=25482 (Caused by NewConnectionError('<requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x11bda4358>: Failed to establish a new connection: [Errno 60] Operation timed out',))"
     ]
    }
   ],
   "source": [
    "#レビュー内容（レビュアーID、タイトル、ポイント、レビュー日付）を取得\n",
    "\n",
    "#リストを用意\n",
    "ID2_list = []\n",
    "title_list = []\n",
    "point_list = []\n",
    "reviewDate_list = []\n",
    "\n",
    "for ID in ID1_list_split[0]: #毎回変更\n",
    "    url = 'https://www.jtnews.jp/cgi-bin_o/revper.cgi?&REVPER_NO='\n",
    "    \n",
    "    ID_first_url = url + str(ID)\n",
    "\n",
    "    #データ取得\n",
    "    result = requests.get(ID_first_url)\n",
    "    c = result.content\n",
    "\n",
    "    #HTMLを元に、オブジェクトを作る\n",
    "    soup = BeautifulSoup(c, \"lxml\")\n",
    "\n",
    "    #リストの部分を切り出し\n",
    "    summary = soup.find_all(\"td\",{'valign':'TOP'})\n",
    "\n",
    "    #2つのテーブルを抜き出し\n",
    "    tables = summary[2].find_all('table',{'bgcolor':'#4499FF'})\n",
    "\n",
    "    #プロフィールの方からtrを抜き出し\n",
    "    trs = tables[0].find_all('tr', {'bgcolor':'#FFFFFF'})\n",
    "    \n",
    "    #ページ数を取得\n",
    "    trs = tables[2].find_all('tr', {'bgcolor':'#FFFFFF'})\n",
    "    last_tr = int(len(trs)/3 - 1)\n",
    "    \n",
    "    if last_tr == 0:\n",
    "        a_last_line = trs[last_tr].find_all('td')\n",
    "    else:\n",
    "        a_last_line = trs[last_tr].find_all('a')\n",
    "    \n",
    "    number_all_a = last_tr * 20 + len(a_last_line)\n",
    "\n",
    "    ID_urls = []\n",
    "    ID_urls.append(ID_first_url)\n",
    "\n",
    "    for i in range(2,int(number_all_a)+1):\n",
    "        ID_url = ID_first_url + '&PAGE_NO=' + str(i)\n",
    "        ID_urls.append(ID_url)\n",
    "    \n",
    "    #レビュアーの各ページをループ\n",
    "    for url in ID_urls:\n",
    "        time.sleep(2) #待機\n",
    "        #データ取得\n",
    "        result = requests.get(url)\n",
    "        c = result.content\n",
    "\n",
    "        #HTMLを元に、オブジェクトを作る\n",
    "        soup = BeautifulSoup(c, \"lxml\")\n",
    "\n",
    "        #リストの部分を切り出し\n",
    "        summary = soup.find_all(\"td\",{'valign':'TOP'})\n",
    "\n",
    "        #2つのテーブルを抜き出し\n",
    "        tables = summary[2].find_all('table',{'bgcolor':'#4499FF'})\n",
    "\n",
    "        #プロフィールの方からtrを抜き出し\n",
    "        trs = tables[0].find_all('tr', {'bgcolor':'#FFFFFF'})\n",
    "\n",
    "        #レビュー情報取得\n",
    "        trs = tables[3].find_all('tr',{'bgcolor':'#FFFFFF'})\n",
    "\n",
    "        latest_point = 0\n",
    "\n",
    "        for i in range(len(trs)):\n",
    "            ths = trs[i].find_all('th')\n",
    "            tds = trs[i].find_all('td')\n",
    "            \n",
    "            #点数取得\n",
    "            point = str(ths)\n",
    "            point = point.replace('[<th style=\"text-align:center\">','')\n",
    "            point = point.replace('</th>]','')\n",
    "\n",
    "            #ポイントが空白なら引き継ぎ、数字なら更新\n",
    "            if point is not '':\n",
    "                latest_point = point\n",
    "\n",
    "            point_list.append(latest_point)\n",
    "\n",
    "            #タイトル取得\n",
    "            title = tds[0].a.attrs['title']\n",
    "\n",
    "            title_list.append(title)\n",
    "\n",
    "            #レビュー日付取得\n",
    "            reviewDate = str(tds[1])\n",
    "            reviewDate = reviewDate.replace('<td style=\"text-align:center\">','')\n",
    "            reviewDate = reviewDate.replace('</td>','')\n",
    "\n",
    "            reviewDate_list.append(reviewDate)\n",
    "            \n",
    "            ID2_list.append(str(ID))\n",
    "\n",
    "        time.sleep(2) #待機\n",
    "    \n",
    "    time.sleep(2) #待機"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ID2_list = Series(ID2_list)\n",
    "title_list = Series(title_list)\n",
    "point_list = Series(point_list)\n",
    "reviewDate_list = Series(reviewDate_list)\n",
    "\n",
    "movie_review_df = pd.concat([ID2_list, title_list, point_list, reviewDate_list],axis=1)\n",
    "\n",
    "#カラム名\n",
    "movie_review_df.columns=['ID2','Title','Point','Review_Date']\n",
    "\n",
    "#csvファイルとして保存                ファイル名毎回変更\n",
    "movie_review_df.to_csv('movie_review0.csv', sep = '\\t',encoding='utf-16')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
